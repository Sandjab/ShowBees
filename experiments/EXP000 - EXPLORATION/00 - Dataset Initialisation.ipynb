{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-08-18/14:59:34.289|14.5%|69.5%|0.26GB] Dataset creation. This may take up to 10 mn. Go grab a coffee.\n",
      "[2020-08-18/14:59:34.290|00.0%|69.5%|0.26GB] >>>>> Starting Dataset MAIN1000 build\n",
      "[2020-08-18/14:59:34.314|40.0%|69.5%|0.26GB] Starting to process 48 audio files.\n",
      "[2020-08-18/15:05:58.900|48.8%|57.1%|0.26GB] Creating Database\n",
      "[2020-08-18/15:05:58.999|62.5%|57.0%|0.26GB] Database created\n",
      "[2020-08-18/15:05:59.003|37.5%|56.9%|0.26GB] Please wait, computing checksum...\n",
      "[2020-08-18/15:06:08.284|11.9%|59.1%|0.26GB]   Computed checksum 964a87370f449298e0ef681efe6094bb\n",
      "[2020-08-18/15:06:08.285|00.0%|59.1%|0.26GB]   Expected checksum 1ba14f84b713fcaf1c7dccff8b1e36a7\n",
      "[2020-08-18/15:06:08.285|00.0%|59.1%|0.26GB] >>>>> Dataset MAIN1000 successfully created.\n",
      "[2020-08-18/15:06:08.285|00.0%|59.1%|0.26GB] ------------------------------------------------------\n",
      "[2020-08-18/15:06:08.285|00.0%|59.1%|0.26GB] DATASET NAME          : MAIN1000\n",
      "[2020-08-18/15:06:08.285|00.0%|59.1%|0.26GB] DATASET PATH          : D:\\Jupyter\\ShowBees\\datasets\\MAIN1000\n",
      "[2020-08-18/15:06:08.286|00.0%|59.1%|0.26GB] DATASET DB PATH       : D:\\Jupyter\\ShowBees\\datasets\\MAIN1000\\MAIN1000.db\n",
      "[2020-08-18/15:06:08.286|00.0%|59.1%|0.26GB] DATASET SAMPLES PATH  : D:\\Jupyter\\ShowBees\\datasets\\MAIN1000\\samples\n",
      "[2020-08-18/15:06:08.286|00.0%|59.1%|0.26GB] NB SOURCE AUDIO FILES : 48\n",
      "[2020-08-18/15:06:08.286|00.0%|59.1%|0.26GB] SAMPLE RATE           : 22050\n",
      "[2020-08-18/15:06:08.286|00.0%|59.1%|0.26GB] DURATION              : 1.0\n",
      "[2020-08-18/15:06:08.286|00.0%|59.1%|0.26GB] OVERLAP               : 0.0\n",
      "[2020-08-18/15:06:08.286|00.0%|59.1%|0.26GB] NB AUDIO CHUNKS       : 24788\n",
      "[2020-08-18/15:06:08.287|00.0%|59.1%|0.26GB] ------------------------------------------------------\n",
      "[2020-08-18/15:06:08.518|13.2%|59.3%|0.26GB] 24788 samples were processed for 'queen' label\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a5a9305fce47b1bc1996cad5a0147e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Annotating nobee', max=48.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-08-18/15:06:15.653|18.1%|55.4%|0.21GB] 24788 samples were processed for 'nobee' label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hive</th>\n",
       "      <th>queen</th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CF001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CF003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CJ001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GH001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hive1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hive1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hive3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hive3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hive  queen  count(*)\n",
       "0  CF001    0.0        14\n",
       "1  CF003    1.0      3649\n",
       "2  CJ001    0.0       790\n",
       "3  GH001    1.0      1396\n",
       "4  Hive1    0.0      1473\n",
       "5  Hive1    1.0      2684\n",
       "6  Hive3    0.0      6545\n",
       "7  Hive3    1.0       654"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings                            # This block prevents display of harmless warnings, but should be\n",
    "warnings.filterwarnings('ignore')          # commented out till the final version, to avoid missing \"real\" warnings\n",
    "\n",
    "import kilroy_was_here                        # Mandatory. Allow access to shared python code from repository root\n",
    "from audace.jupytools import iprint           # timstamped (to the ms) print with CPU and RAM consumption information\n",
    "from audace.audiodataset import AudioDataset  # Class for audio dataset handling\n",
    "from audace import providers\n",
    "from audace import transformers\n",
    "from audace import featurizers\n",
    "\n",
    "\n",
    "# Path where to find initial annotated dataset (audio and lab files)\n",
    "SOURCE_PATH ='/Users/jpg/Documents/Nolasco'\n",
    "\n",
    "# Dataset name is the master key for dataset adressing. Change it according to the\n",
    "# dataset you wan to generate\n",
    "DATASET_NAME = 'MAIN1000'\n",
    "\n",
    "          #############################\n",
    "########### Initialize Dataset Object #\n",
    "          #############################\n",
    "try:\n",
    "    #By providing a source path,we implicitly indicates that you want to CREATE the data set.\n",
    "    # Run with a pool of 4 processes\n",
    "    iprint(\"Dataset creation. This may take up to 10 mn. Go grab a coffee.\")\n",
    "    ds = AudioDataset(DATASET_NAME, SOURCE_PATH, nprocs=4)\n",
    "    \n",
    "except FileExistsError:\n",
    "    # To allow rerun, we catch the exception in case the dataset was already created.\n",
    "    # Ideally, you should create the dataset once for all in a dedicated notebook,\n",
    "    # and then retrieve it from other notebooks when needed\n",
    "    # Here, by not providing a source path, we implicitly express the intent of RETRIEVING\n",
    "    # an existing dataset rather than CREATING a new one\n",
    "    iprint(\"Failing back to existing dataset retrieval\")\n",
    "    ds = AudioDataset(DATASET_NAME)\n",
    "    iprint(\"Dataset retrieved\")\n",
    "    \n",
    "# Display AudioDataset summary   \n",
    "ds.info()\n",
    "\n",
    "          ##################\n",
    "########### Compute Labels #\n",
    "          ##################\n",
    "ds.addLabel(\"nobee\")\n",
    "ds.addLabel(\"queen\")\n",
    "\n",
    "# The \"queen\" label value is deduced from the source file name, using a StringMapper transformer\n",
    "# This transformer iterates over a list 2-uples (regular expression, target value) and return\n",
    "# the target value as soon as a match is found. Thus, you must order your list from stricter to looser\n",
    "trsfrm_queen = transformers.StringMapper(\n",
    "        [('(?i)active', 1), \n",
    "         ('(?i)missing queen', 0),\n",
    "         ('NO_QueenBee', 0),\n",
    "         ('QueenBee', 1)     \n",
    "        ])\n",
    "\n",
    "# The transformer is then used over the source filenames, using the FromFileName labelizer\n",
    "# This labelizer does not provide label strength.\n",
    "\n",
    "n = ds.setLabel('queen', providers.FromFileName(trsfrm_queen))\n",
    "iprint(n, \"samples were processed for 'queen' label\")\n",
    "\n",
    "# The \"nobee\" label value comes from annotation files, (.lab files using the same base name as the audio\n",
    "# source file they annotate), using the FromAnnotation labelizer, with no transformation.\n",
    "# This labelizer takes 2 arguments:\n",
    "# - a mandatory source path, pointing to the directory where the .lab files reside\n",
    "# - an optional threshold, allowing to disregard any \"label\" event with a duration under this treshold\n",
    "# The label strength over a sample is computed by summing the duration of \"label\" events (if > th) and dividing\n",
    "# this sum by the sample duration.\n",
    "\n",
    "# Here we use a 0.0s threshold\n",
    "n = ds.setLabel('nobee', providers.FromAnnotation(SOURCE_PATH, th=0.0))\n",
    "iprint(n, \"samples were processed for 'nobee' label\")\n",
    "\n",
    "\n",
    "          ######################\n",
    "########### Compute Attributes #\n",
    "          ######################\n",
    "#The string matcher transformer behave differently than the StringMapper. It uses regexp\n",
    "# capture group to retrieve part pf a string matching a specific pattern. This can be used\n",
    "# either for complex or very basic matching. Here we just ask for the five first chars,\n",
    "# provided they belong to characters valid for identifiers (A-Z, a-z,0-9 and underscore)\n",
    "ds.addAttribute('hive')\n",
    "ds.setAttribute('hive', providers.FromFileName(transformers.StringMatcher(\"^(\\w{5})\")))\n",
    "\n",
    "\n",
    "# Compute attribute fold from hive\n",
    "ds.addAttribute('fold')\n",
    "\n",
    "e = {'CF001':1, 'CF003':1, 'CJ001':2, 'GH001':2, 'Hive1':3, 'Hive3': 4}\n",
    "ds.setAttribute('fold', providers.FromQuery('hive', transformers.Decode(e)))\n",
    "\n",
    "\n",
    "# Display dataset as a pandas dataframe\n",
    "ds.dumpDataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>queen</th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  queen  count(*)\n",
       "0     1    0.0        14\n",
       "1     1    1.0      3649\n",
       "2     2    0.0       790\n",
       "3     2    1.0      1396\n",
       "4     3    0.0      1473\n",
       "5     3    1.0      2684\n",
       "6     4    0.0      6545\n",
       "7     4    1.0       654"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display cardinalities by fold attribute and queen label for samples with no external perturbation\n",
    "sql = \"\"\"\n",
    "    select distinct fold, queen, count(*)\n",
    "    from samples\n",
    "    where nobee = 0\n",
    "    group by fold, queen\n",
    "    order by fold\n",
    "    \"\"\"\n",
    "ds.queryDataFrame(sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
